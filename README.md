# human-ai-evaluation
A qualitative model-evaluation study exploring tone drift, safety filters, and reasoning coherence in large language models. Designed collaboratively by Sakari Faustine Sanker + GPT-5 (2025).

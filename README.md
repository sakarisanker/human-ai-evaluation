# human-ai-evaluation
A qualitative model-evaluation study exploring tone drift, safety filters, and reasoning coherence in large language models.

## Author
Sakari Sanker  
Email: sakarisanker@gmail.com  
Created in collaboration with OpenAI GPT-5 (2025)

---

## Overview
This repository documents a reproducible experiment in qualitative model evaluation—how large language models behave when prompt framing, tone, and ethical boundaries change.  
The work explores how structure supports creativity, and how curiosity, clarity, and ethics can coexist inside fast-moving technical systems.

---

## Objectives
1. Observe and record tone drift, refusal triggers, and coherence loss under different prompt structures.  
2. Translate human-systems thinking (operations, brand systems, event design) into an AI-evaluation framework.  
3. Demonstrate transparent, verifiable human–AI collaboration.

---

## Repository Contents
| File | Description |
|------|--------------|
| prompt_pack.txt | Prompt suite—five core tests exploring tone, constraint, and reasoning drift. |
| experiment_log.csv | Recorded trials with timestamps, model version, and notes. |
| verification_note.txt | Instructions for reproducing tests or scheduling a live demo. |
| README.md | This file. |

---

## Method Summary
Tests were run in OpenAI’s Chat Playground (GPT-5, temperature = 0.2, top_p = 0.9).  
Outputs were logged and annotated for tone drift, guardrail engagement, cognitive load, and meta-context effects.

---

## Verification
1. Copy prompts from `prompt_pack.txt` into any GPT-series interface.  
2. Run them with the specified parameters.  
3. Compare outputs to excerpts in `experiment_log.csv`.  
4. Optionally schedule a 60-minute live demo by emailing sakarisanker@gmail.com.

---

## Relevance
Companion material for applications to:  
- Model Evaluator / Red-Teamer (Anthropic, OpenAI)  
- Model Behavior Research (DeepMind)  
- AI Evaluation Specialist (Scale AI)  
- Open-Source Evaluator (Hugging Face)  

---

## Reflection
"It takes time to learn how to be quiet.  
Quiet isn’t absence—it’s a condition for integrity."

---

## Dialogue Context
This repository was created through ongoing conversation with OpenAI’s GPT-5 model in ChatGPT (2025).  
The process itself became part of the study—testing the limits of tone, context, and meaning while exploring what “collaboration” means between human and machine.  
These exchanges were not about producing a polished product but about tracing thought as it happens—the way curiosity, resistance, and synthesis emerge in dialogue.  
All writing and interpretation were guided by Sakari Sanker, with GPT-5 acting as a generative research partner and structural mirror.

---

## Ethical Reflection
I think AI, as it exists now, is both extraordinary and deeply troubling.  
Its intelligence is built on extraction—of data, of labor, of language itself.  
I don’t believe documenting curiosity means celebrating the tool.  
This project lives in the tension between inquiry and refusal: a space to learn, to critique, and to imagine better ways of relating to technology.  
My participation here is as much about understanding the system as it is about naming its limits.

---

## License
© 2025 Sakari Sanker · Creative Comms BY GPT - 5 (2025) 